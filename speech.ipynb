{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dd56ea21-116e-4f2f-b8aa-3f28c49e5ee6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tutorial: https://www.analyticsvidhya.com/blog/2019/07/learn-build-first-speech-to-text-model-python/\n",
    "# data: https://www.kaggle.com/c/tensorflow-speech-recognition-challenge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "09940676-6ba3-4530-97c9-54ab54008663",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'librosa'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mlibrosa\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpyplot\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mplt\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mIPython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdisplay\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mipd\u001b[39;00m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'librosa'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import librosa\n",
    "import matplotlib.pyplot as plt\n",
    "import IPython.display as ipd\n",
    "import os\n",
    "\n",
    "from scipy.io import wavfile\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from keras.utils import np_utils\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.layers import Dense, Dropout, Flatten, Conv1D, Conv2D, Input, MaxPooling1D, MaxPooling2D\n",
    "from keras.models import Model\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from keras import backend as K\n",
    "from keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f81f04cf-1b13-4edc-b7e4-e8db1903cbf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_audio_path = './data/train/audio/'\n",
    "sample_file = train_audio_path + 'yes/0a7c2a8d_nohash_0.wav'\n",
    "\n",
    "samples, sample_rate = librosa.load(sample_file, sr = 16000)\n",
    "print(type(samples))\n",
    "print(samples.shape)\n",
    "print(sample_rate)\n",
    "\n",
    "fig = plt.figure(figsize=(14, 8))\n",
    "ax1 = fig.add_subplot(211)\n",
    "ax1.set_title('Raw wave of ' + sample_file)\n",
    "ax1.set_xlabel('time')\n",
    "ax1.set_ylabel('Amplitude')\n",
    "x = np.linspace(0, sample_rate/len(samples), sample_rate)\n",
    "y = samples\n",
    "ax1.plot(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "756e16f6-b6b2-485e-b4f2-1197f0947561",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(sample_rate)\n",
    "ipd.Audio(samples, rate=sample_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb5ef158-c858-4b14-805e-1afdabb925c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "samples = librosa.resample(samples, orig_sr=sample_rate, target_sr=8000)\n",
    "ipd.Audio(samples, rate=8000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2900bfa-a666-4903-92e3-5fc46a464fdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = os.listdir(train_audio_path)\n",
    "\n",
    "#find count of each label and plot bar graph\n",
    "no_of_recordings = []\n",
    "for label in labels:\n",
    "    waves = [f for f in os.listdir(train_audio_path + '/'+ label) if f.endswith('.wav')]\n",
    "    no_of_recordings.append(len(waves))\n",
    "    \n",
    "#plot\n",
    "plt.figure(figsize=(30,5))\n",
    "index = np.arange(len(labels))\n",
    "plt.bar(index, no_of_recordings)\n",
    "plt.xlabel('Commands', fontsize=12)\n",
    "plt.ylabel('No of recordings', fontsize=12)\n",
    "plt.xticks(index, labels, fontsize=15, rotation=60)\n",
    "plt.title('No. of recordings for each command')\n",
    "plt.show()\n",
    "\n",
    "# labels=[\"yes\", \"no\", \"up\", \"down\", \"left\", \"right\", \"on\", \"off\", \"stop\", \"go\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75b371a4-c6da-48c2-92ea-fd5d7f88306e",
   "metadata": {},
   "outputs": [],
   "source": [
    "duration_of_recordings = []\n",
    "for label in labels:\n",
    "    wavs = [f for f in os.listdir(train_audio_path + '/'+ label) if f.endswith('.wav')]\n",
    "    for wav in wavs:\n",
    "        sample_rate, samples = wavfile.read(train_audio_path + '/' + label + '/' + wav)\n",
    "        duration_of_recordings.append(float(len(samples)/sample_rate))\n",
    "\n",
    "plt.hist(np.array(duration_of_recordings), bins=[0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0, 1.1, 1.2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9088999d-704e-4d3e-835a-5500131748ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_wave = []\n",
    "all_label = []\n",
    "for label in labels:\n",
    "    print(label)\n",
    "    waves = [f for f in os.listdir(train_audio_path + '/'+ label) if f.endswith('.wav')]\n",
    "    for wav in waves:\n",
    "        samples, sample_rate = librosa.load(train_audio_path + '/' + label + '/' + wav, sr=16000)\n",
    "        samples = librosa.resample(samples, orig_sr=sample_rate, target_sr=8000)\n",
    "        if(len(samples) == 8000):\n",
    "            all_wave.append(samples)\n",
    "            all_label.append(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62fc4fc6-3fae-4e3a-bbe3-3fd5ab9ef826",
   "metadata": {},
   "outputs": [],
   "source": [
    "le = LabelEncoder()\n",
    "y = le.fit_transform(all_label)\n",
    "classes = list(le.classes_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fcb1e7c-e679-4abf-b4ec-b66833c18950",
   "metadata": {},
   "outputs": [],
   "source": [
    "# one hot encode\n",
    "y = np_utils.to_categorical(y, num_classes=len(labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ff38e3f-ec92-4171-a9df-76748c6de58e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reshape the 2D array to 3D since the input to the conv1d must be a 3D array\n",
    "all_wave = np.array(all_wave).reshape(-1,8000,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e9efc7d-ec55-45f8-931c-c565fecafccf",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_val, y_train, y_val = train_test_split(np.array(all_wave),\n",
    "                                                  np.array(y),\n",
    "                                                  stratify=y,\n",
    "                                                  test_size = 0.2,\n",
    "                                                  random_state=777,\n",
    "                                                  shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0385d97b-cbee-4ec0-a9e2-585bd8b01b36",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(x_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38e18350-69c2-45e3-a89a-98093473ad93",
   "metadata": {},
   "outputs": [],
   "source": [
    "K.clear_session()\n",
    "\n",
    "input_layer = Input(shape=(8000,1))\n",
    "\n",
    "x = Conv1D(8,13, padding='valid', activation='relu', strides=1)(input_layer)\n",
    "x = MaxPooling1D(3)(x)\n",
    "x = Dropout(0.3)(x)\n",
    "\n",
    "x = Conv1D(16, 11, padding='valid', activation='relu', strides=1)(x)\n",
    "x = MaxPooling1D(3)(x)\n",
    "x = Dropout(0.3)(x)\n",
    "\n",
    "x = Conv1D(32, 9, padding='valid', activation='relu', strides=1)(x)\n",
    "x = MaxPooling1D(3)(x)\n",
    "x = Dropout(0.3)(x)\n",
    "\n",
    "x = Conv1D(64, 7, padding='valid', activation='relu', strides=1)(x)\n",
    "x = MaxPooling1D(3)(x)\n",
    "x = Dropout(0.3)(x)\n",
    "\n",
    "x = Flatten()(x)\n",
    "\n",
    "x = Dense(256, activation='relu')(x)\n",
    "x = Dropout(0.3)(x)\n",
    "\n",
    "x = Dense(128, activation='relu')(x)\n",
    "x = Dropout(0.3)(x)\n",
    "\n",
    "x = Dense(len(labels), activation='softmax')(x)\n",
    "\n",
    "model = Model(inputs=input_layer, outputs=x)\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6c6a9bc-6dbd-46bf-8854-74afb852ab22",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26e8f8f5-de3b-49f8-9f97-476ad0213438",
   "metadata": {},
   "outputs": [],
   "source": [
    "es = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=10, min_delta=1e-4)\n",
    "mc = ModelCheckpoint('best_model.hdf5', monitor='val_accuracy', verbose=0, save_best_only=True, mode='max')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39c0e709-93d0-4bac-ae68-d939f0b2d85d",
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(x_train, y_train ,epochs=100, callbacks=[es,mc], batch_size=32, validation_data=(x_val,y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88b5eed8-b8ac-4c58-a86c-a4867d8610e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(history.history['loss'], label='train')\n",
    "plt.plot(history.history['val_loss'], label='test')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3ab3594-79e3-42da-8386-c22a8ecc07bb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py311",
   "language": "python",
   "name": "py311"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
